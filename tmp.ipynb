{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m trunc_normal_, DropPath\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregistry\u001b[39;00m \u001b[39mimport\u001b[39;00m register_model\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'timm'"
     ]
    }
   ],
   "source": [
    "# Copyright 2022 Garena Online Private Limited\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"\n",
    "MetaFormer baselines including IdentityFormer, RandFormer, PoolFormerV2,\n",
    "ConvFormer and CAFormer.\n",
    "Some implementations are modified from timm (https://github.com/rwightman/pytorch-image-models).\n",
    "\"\"\"\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from timm.models.layers import trunc_normal_, DropPath\n",
    "from timm.models.registry import register_model\n",
    "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.models.layers.helpers import to_2tuple\n",
    "\n",
    "\n",
    "def _cfg(url='', **kwargs):\n",
    "    return {\n",
    "        'url': url,\n",
    "        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': None,\n",
    "        'crop_pct': 1.0, 'interpolation': 'bicubic',\n",
    "        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD, 'classifier': 'head',\n",
    "        **kwargs\n",
    "    }\n",
    "\n",
    "\n",
    "default_cfgs = {\n",
    "    'convformer_s18_in21ft1k': _cfg(\n",
    "        url='https://huggingface.co/sail/dl/resolve/main/convformer/convformer_s18_in21ft1k.pth')}\n",
    "\n",
    "\n",
    "class Downsampling(nn.Module):\n",
    "    \"\"\"\n",
    "    Downsampling implemented by a layer of convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, \n",
    "        kernel_size, stride=1, padding=0, \n",
    "        pre_norm=None, post_norm=None, pre_permute=False):\n",
    "        super().__init__()\n",
    "        self.pre_norm = pre_norm(in_channels) if pre_norm else nn.Identity()\n",
    "        self.pre_permute = pre_permute\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n",
    "                              stride=stride, padding=padding)\n",
    "        self.post_norm = post_norm(out_channels) if post_norm else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_norm(x)\n",
    "        if self.pre_permute:\n",
    "            # if take [B, H, W, C] as input, permute it to [B, C, H, W]\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "        x = self.conv(x)\n",
    "        x = x.permute(0, 2, 3, 1) # [B, C, H, W] -> [B, H, W, C]\n",
    "        x = self.post_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Scale(nn.Module):\n",
    "    \"\"\"\n",
    "    Scale vector by element multiplications.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, init_value=1.0, trainable=True):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(init_value * torch.ones(dim), requires_grad=trainable)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.scale\n",
    "        \n",
    "\n",
    "class SquaredReLU(nn.Module):\n",
    "    \"\"\"\n",
    "        Squared ReLU: https://arxiv.org/abs/2109.08668\n",
    "    \"\"\"\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "    def forward(self, x):\n",
    "        return torch.square(self.relu(x))\n",
    "\n",
    "\n",
    "class StarReLU(nn.Module):\n",
    "    \"\"\"\n",
    "    StarReLU: s * relu(x) ** 2 + b\n",
    "    \"\"\"\n",
    "    def __init__(self, scale_value=1.0, bias_value=0.0,\n",
    "        scale_learnable=True, bias_learnable=True, \n",
    "        mode=None, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        self.scale = nn.Parameter(scale_value * torch.ones(1),\n",
    "            requires_grad=scale_learnable)\n",
    "        self.bias = nn.Parameter(bias_value * torch.ones(1),\n",
    "            requires_grad=bias_learnable)\n",
    "    def forward(self, x):\n",
    "        return self.scale * self.relu(x)**2 + self.bias\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Vanilla self-attention from Transformer: https://arxiv.org/abs/1706.03762.\n",
    "    Modified from timm.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, head_dim=32, num_heads=None, qkv_bias=False,\n",
    "        attn_drop=0., proj_drop=0., proj_bias=False, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head_dim = head_dim\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.num_heads = num_heads if num_heads else dim // head_dim\n",
    "        if self.num_heads == 0:\n",
    "            self.num_heads = 1\n",
    "        \n",
    "        self.attention_dim = self.num_heads * self.head_dim\n",
    "\n",
    "        self.qkv = nn.Linear(dim, self.attention_dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(self.attention_dim, dim, bias=proj_bias)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, H, W, C = x.shape\n",
    "        N = H * W\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv.unbind(0)   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, H, W, self.attention_dim)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RandomMixing(nn.Module):\n",
    "    def __init__(self, num_tokens=196, **kwargs):\n",
    "        super().__init__()\n",
    "        self.random_matrix = nn.parameter.Parameter(\n",
    "            data=torch.softmax(torch.rand(num_tokens, num_tokens), dim=-1), \n",
    "            requires_grad=False)\n",
    "    def forward(self, x):\n",
    "        B, H, W, C = x.shape\n",
    "        x = x.reshape(B, H*W, C)\n",
    "        x = torch.einsum('mn, bnc -> bmc', self.random_matrix, x)\n",
    "        x = x.reshape(B, H, W, C)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LayerNormGeneral(nn.Module):\n",
    "    r\"\"\" General LayerNorm for different situations.\n",
    "\n",
    "    Args:\n",
    "        affine_shape (int, list or tuple): The shape of affine weight and bias.\n",
    "            Usually the affine_shape=C, but in some implementation, like torch.nn.LayerNorm,\n",
    "            the affine_shape is the same as normalized_dim by default. \n",
    "            To adapt to different situations, we offer this argument here.\n",
    "        normalized_dim (tuple or list): Which dims to compute mean and variance. \n",
    "        scale (bool): Flag indicates whether to use scale or not.\n",
    "        bias (bool): Flag indicates whether to use scale or not.\n",
    "\n",
    "        We give several examples to show how to specify the arguments.\n",
    "\n",
    "        LayerNorm (https://arxiv.org/abs/1607.06450):\n",
    "            For input shape of (B, *, C) like (B, N, C) or (B, H, W, C),\n",
    "                affine_shape=C, normalized_dim=(-1, ), scale=True, bias=True;\n",
    "            For input shape of (B, C, H, W),\n",
    "                affine_shape=(C, 1, 1), normalized_dim=(1, ), scale=True, bias=True.\n",
    "\n",
    "        Modified LayerNorm (https://arxiv.org/abs/2111.11418)\n",
    "            that is idental to partial(torch.nn.GroupNorm, num_groups=1):\n",
    "            For input shape of (B, N, C),\n",
    "                affine_shape=C, normalized_dim=(1, 2), scale=True, bias=True;\n",
    "            For input shape of (B, H, W, C),\n",
    "                affine_shape=C, normalized_dim=(1, 2, 3), scale=True, bias=True;\n",
    "            For input shape of (B, C, H, W),\n",
    "                affine_shape=(C, 1, 1), normalized_dim=(1, 2, 3), scale=True, bias=True.\n",
    "\n",
    "        For the several metaformer baslines,\n",
    "            IdentityFormer, RandFormer and PoolFormerV2 utilize Modified LayerNorm without bias (bias=False);\n",
    "            ConvFormer and CAFormer utilizes LayerNorm without bias (bias=False).\n",
    "    \"\"\"\n",
    "    def __init__(self, affine_shape=None, normalized_dim=(-1, ), scale=True, \n",
    "        bias=True, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.normalized_dim = normalized_dim\n",
    "        self.use_scale = scale\n",
    "        self.use_bias = bias\n",
    "        self.weight = nn.Parameter(torch.ones(affine_shape)) if scale else None\n",
    "        self.bias = nn.Parameter(torch.zeros(affine_shape)) if bias else None\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        c = x - x.mean(self.normalized_dim, keepdim=True)\n",
    "        s = c.pow(2).mean(self.normalized_dim, keepdim=True)\n",
    "        x = c / torch.sqrt(s + self.eps)\n",
    "        if self.use_scale:\n",
    "            x = x * self.weight\n",
    "        if self.use_bias:\n",
    "            x = x + self.bias\n",
    "        return x\n",
    "\n",
    "\n",
    "class LayerNormWithoutBias(nn.Module):\n",
    "    \"\"\"\n",
    "    Equal to partial(LayerNormGeneral, bias=False) but faster, \n",
    "    because it directly utilizes otpimized F.layer_norm\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-5, **kwargs):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.bias = None\n",
    "        if isinstance(normalized_shape, int):\n",
    "            normalized_shape = (normalized_shape,)\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.normalized_shape = normalized_shape\n",
    "    def forward(self, x):\n",
    "        return F.layer_norm(x, self.normalized_shape, weight=self.weight, bias=self.bias, eps=self.eps)\n",
    "\n",
    "\n",
    "class SepConv(nn.Module):\n",
    "    r\"\"\"\n",
    "    Inverted separable convolution from MobileNetV2: https://arxiv.org/abs/1801.04381.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, expansion_ratio=2,\n",
    "        act1_layer=StarReLU, act2_layer=nn.Identity, \n",
    "        bias=False, kernel_size=7, padding=3,\n",
    "        **kwargs, ):\n",
    "        super().__init__()\n",
    "        med_channels = int(expansion_ratio * dim)\n",
    "        self.pwconv1 = nn.Linear(dim, med_channels, bias=bias)\n",
    "        self.act1 = act1_layer()\n",
    "        self.dwconv = nn.Conv2d(\n",
    "            med_channels, med_channels, kernel_size=kernel_size,\n",
    "            padding=padding, groups=med_channels, bias=bias) # depthwise conv\n",
    "        self.act2 = act2_layer()\n",
    "        self.pwconv2 = nn.Linear(med_channels, dim, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.act2(x)\n",
    "        x = self.pwconv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Pooling(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of pooling for PoolFormer: https://arxiv.org/abs/2111.11418\n",
    "    Modfiled for [B, H, W, C] input\n",
    "    \"\"\"\n",
    "    def __init__(self, pool_size=3, **kwargs):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AvgPool2d(\n",
    "            pool_size, stride=1, padding=pool_size//2, count_include_pad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x.permute(0, 3, 1, 2)\n",
    "        y = self.pool(y)\n",
    "        y = y.permute(0, 2, 3, 1)\n",
    "        return y - x\n",
    "\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    \"\"\" MLP as used in MetaFormer models, eg Transformer, MLP-Mixer, PoolFormer, MetaFormer baslines and related networks.\n",
    "    Mostly copied from timm.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, mlp_ratio=4, out_features=None, act_layer=StarReLU, drop=0., bias=False, **kwargs):\n",
    "        super().__init__()\n",
    "        in_features = dim\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = int(mlp_ratio * in_features)\n",
    "        drop_probs = to_2tuple(drop)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features, bias=bias)\n",
    "        self.act = act_layer()\n",
    "        self.drop1 = nn.Dropout(drop_probs[0])\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features, bias=bias)\n",
    "        self.drop2 = nn.Dropout(drop_probs[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MlpHead(nn.Module):\n",
    "    \"\"\" MLP classification head\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, num_classes=1000, mlp_ratio=4, act_layer=SquaredReLU,\n",
    "        norm_layer=nn.LayerNorm, head_dropout=0., bias=True):\n",
    "        super().__init__()\n",
    "        hidden_features = int(mlp_ratio * dim)\n",
    "        self.fc1 = nn.Linear(dim, hidden_features, bias=bias)\n",
    "        self.act = act_layer()\n",
    "        self.norm = norm_layer(hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, num_classes, bias=bias)\n",
    "        self.head_dropout = nn.Dropout(head_dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.head_dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MetaFormerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of one MetaFormer block.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim,\n",
    "                 token_mixer=nn.Identity, mlp=Mlp,\n",
    "                 norm_layer=nn.LayerNorm,\n",
    "                 drop=0., drop_path=0.,\n",
    "                 layer_scale_init_value=None, res_scale_init_value=None\n",
    "                 ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.token_mixer = token_mixer(dim=dim, drop=drop)\n",
    "        self.drop_path1 = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.layer_scale1 = Scale(dim=dim, init_value=layer_scale_init_value) \\\n",
    "            if layer_scale_init_value else nn.Identity()\n",
    "        self.res_scale1 = Scale(dim=dim, init_value=res_scale_init_value) \\\n",
    "            if res_scale_init_value else nn.Identity()\n",
    "\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        self.mlp = mlp(dim=dim, drop=drop)\n",
    "        self.drop_path2 = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.layer_scale2 = Scale(dim=dim, init_value=layer_scale_init_value) \\\n",
    "            if layer_scale_init_value else nn.Identity()\n",
    "        self.res_scale2 = Scale(dim=dim, init_value=res_scale_init_value) \\\n",
    "            if res_scale_init_value else nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.res_scale1(x) + \\\n",
    "            self.layer_scale1(\n",
    "                self.drop_path1(\n",
    "                    self.token_mixer(self.norm1(x))\n",
    "                )\n",
    "            )\n",
    "        x = self.res_scale2(x) + \\\n",
    "            self.layer_scale2(\n",
    "                self.drop_path2(\n",
    "                    self.mlp(self.norm2(x))\n",
    "                )\n",
    "            )\n",
    "        return x\n",
    "\n",
    "\n",
    "r\"\"\"\n",
    "downsampling (stem) for the first stage is a layer of conv with k7, s4 and p2\n",
    "downsamplings for the last 3 stages is a layer of conv with k3, s2 and p1\n",
    "DOWNSAMPLE_LAYERS_FOUR_STAGES format: [Downsampling, Downsampling, Downsampling, Downsampling]\n",
    "use `partial` to specify some arguments\n",
    "\"\"\"\n",
    "DOWNSAMPLE_LAYERS_FOUR_STAGES = [partial(Downsampling,\n",
    "            kernel_size=7, stride=4, padding=2,\n",
    "            post_norm=partial(LayerNormGeneral, bias=False, eps=1e-6)\n",
    "            )] + \\\n",
    "            [partial(Downsampling,\n",
    "                kernel_size=3, stride=2, padding=1, \n",
    "                pre_norm=partial(LayerNormGeneral, bias=False, eps=1e-6), pre_permute=True\n",
    "            )]*3\n",
    "\n",
    "\n",
    "class MetaFormer(nn.Module):\n",
    "    r\"\"\" MetaFormer\n",
    "        A PyTorch impl of : `MetaFormer Baselines for Vision`  -\n",
    "          https://arxiv.org/abs/2210.13452\n",
    "\n",
    "    Args:\n",
    "        in_chans (int): Number of input image channels. Default: 3.\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000.\n",
    "        depths (list or tuple): Number of blocks at each stage. Default: [2, 2, 6, 2].\n",
    "        dims (int): Feature dimension at each stage. Default: [64, 128, 320, 512].\n",
    "        downsample_layers: (list or tuple): Downsampling layers before each stage.\n",
    "        token_mixers (list, tuple or token_fcn): Token mixer for each stage. Default: nn.Identity.\n",
    "        mlps (list, tuple or mlp_fcn): Mlp for each stage. Default: Mlp.\n",
    "        norm_layers (list, tuple or norm_fcn): Norm layers for each stage. Default: partial(LayerNormGeneral, eps=1e-6, bias=False).\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
    "        head_dropout (float): dropout for MLP classifier. Default: 0.\n",
    "        layer_scale_init_values (list, tuple, float or None): Init value for Layer Scale. Default: None.\n",
    "            None means not use the layer scale. Form: https://arxiv.org/abs/2103.17239.\n",
    "        res_scale_init_values (list, tuple, float or None): Init value for Layer Scale. Default: [None, None, 1.0, 1.0].\n",
    "            None means not use the layer scale. From: https://arxiv.org/abs/2110.09456.\n",
    "        output_norm: norm before classifier head. Default: partial(nn.LayerNorm, eps=1e-6).\n",
    "        head_fn: classification head. Default: nn.Linear.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_chans=3, num_classes=1000, \n",
    "                 depths=[2, 2, 6, 2],\n",
    "                 dims=[64, 128, 320, 512],\n",
    "                 downsample_layers=DOWNSAMPLE_LAYERS_FOUR_STAGES,\n",
    "                 token_mixers=nn.Identity,\n",
    "                 mlps=Mlp,\n",
    "                 norm_layers=partial(LayerNormWithoutBias, eps=1e-6), # partial(LayerNormGeneral, eps=1e-6, bias=False),\n",
    "                 drop_path_rate=0.,\n",
    "                 head_dropout=0.0, \n",
    "                 layer_scale_init_values=None,\n",
    "                 res_scale_init_values=[None, None, 1.0, 1.0],\n",
    "                 output_norm=partial(nn.LayerNorm, eps=1e-6), \n",
    "                 head_fn=nn.Linear,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if not isinstance(depths, (list, tuple)):\n",
    "            depths = [depths] # it means the model has only one stage\n",
    "        if not isinstance(dims, (list, tuple)):\n",
    "            dims = [dims]\n",
    "\n",
    "        num_stage = len(depths)\n",
    "        self.num_stage = num_stage\n",
    "\n",
    "        if not isinstance(downsample_layers, (list, tuple)):\n",
    "            downsample_layers = [downsample_layers] * num_stage\n",
    "        down_dims = [in_chans] + dims\n",
    "        self.downsample_layers = nn.ModuleList(\n",
    "            [downsample_layers[i](down_dims[i], down_dims[i+1]) for i in range(num_stage)]\n",
    "        )\n",
    "        \n",
    "        if not isinstance(token_mixers, (list, tuple)):\n",
    "            token_mixers = [token_mixers] * num_stage\n",
    "\n",
    "        if not isinstance(mlps, (list, tuple)):\n",
    "            mlps = [mlps] * num_stage\n",
    "\n",
    "        if not isinstance(norm_layers, (list, tuple)):\n",
    "            norm_layers = [norm_layers] * num_stage\n",
    "        \n",
    "        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "\n",
    "        if not isinstance(layer_scale_init_values, (list, tuple)):\n",
    "            layer_scale_init_values = [layer_scale_init_values] * num_stage\n",
    "        if not isinstance(res_scale_init_values, (list, tuple)):\n",
    "            res_scale_init_values = [res_scale_init_values] * num_stage\n",
    "\n",
    "        self.stages = nn.ModuleList() # each stage consists of multiple metaformer blocks\n",
    "        cur = 0\n",
    "        for i in range(num_stage):\n",
    "            stage = nn.Sequential(\n",
    "                *[MetaFormerBlock(dim=dims[i],\n",
    "                token_mixer=token_mixers[i],\n",
    "                mlp=mlps[i],\n",
    "                norm_layer=norm_layers[i],\n",
    "                drop_path=dp_rates[cur + j],\n",
    "                layer_scale_init_value=layer_scale_init_values[i],\n",
    "                res_scale_init_value=res_scale_init_values[i],\n",
    "                ) for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "        self.norm = output_norm(dims[-1])\n",
    "\n",
    "        if head_dropout > 0.0:\n",
    "            self.head = head_fn(dims[-1], num_classes, head_dropout=head_dropout)\n",
    "        else:\n",
    "            self.head = head_fn(dims[-1], num_classes)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'norm'}\n",
    "\n",
    "    def forward_features(self, x,additional_features=None):\n",
    "        if additional_features is not None:\n",
    "            x = x + torch.nn.functional.pad(additional_features,\n",
    "                                    [0, 0, 0, 0, 0, x.size(1) - additional_features.size(1)],\n",
    "                                    mode='constant', value=0)\n",
    "        for i in range(self.num_stage):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.stages[i](x)\n",
    "        return self.norm(x.mean([1, 2])) # (B, H, W, C) -> (B, C)\n",
    "\n",
    "    def forward(self, x,additional_features=None):\n",
    "        x = self.forward_features(x,additional_features)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "@register_model\n",
    "def convformer_s18_in21ft1k(pretrained=False, **kwargs):\n",
    "    model = MetaFormer(\n",
    "        depths=[3, 3, 9, 3],\n",
    "        dims=[64, 128, 320, 512],\n",
    "        token_mixers=SepConv,\n",
    "        head_fn=MlpHead,\n",
    "        **kwargs)\n",
    "    model.default_cfg = default_cfgs['convformer_s18_in21ft1k']\n",
    "    if pretrained:\n",
    "        state_dict = torch.hub.load_state_dict_from_url(\n",
    "            url= model.default_cfg['url'], map_location=\"cpu\", check_hash=True)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.9.5-py3-none-any.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from timm) (6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from timm) (0.14.1+cu117)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from timm) (0.10.1)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-win_amd64.whl (263 kB)\n",
      "     -------------------------------------- 263.7/263.7 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.7 in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from timm) (1.13.1+cu117)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from torch>=1.7->timm) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from huggingface-hub->timm) (3.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from huggingface-hub->timm) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from huggingface-hub->timm) (22.0)\n",
      "Requirement already satisfied: requests in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from huggingface-hub->timm) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from torchvision->timm) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from torchvision->timm) (9.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->timm) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\daai.desktop-128vds1\\anaconda3\\lib\\site-packages (from tqdm->huggingface-hub->timm) (0.4.6)\n",
      "Installing collected packages: safetensors, timm\n",
      "Successfully installed safetensors-0.3.1 timm-0.9.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
